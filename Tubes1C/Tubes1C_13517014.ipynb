{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar 1C IF3270 - Machine Learning\n",
    "------------------------------------------\n",
    "##### NIM/Nama  : 13517014/Yoel Susanto | 13517065/Andrian Cedric | 13517131/Jan Meyer Saragih | 13517137/Vincent Budianto\n",
    "##### Nama file : Tubes1C_13517014.ipynb\n",
    "##### Topik     : Implementasi modul myMLP\n",
    "##### Tanggal   : 28 February 2020\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layer import Layer, ActivationFunction\n",
    "from MLP import MLP\n",
    "from sklearn.neural_network import MLPClassifier as skMLP\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as dataset\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Penjelasan Implementasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementasi myMLP\n",
    "\n",
    "Implementasi myMLP dari kelompok kami menggunakan backpropagation, yaitu algoritma neural network dengan multi-layered dan feedforward untuk menentukan keputusan yang ada berdasarkan data training yang dilatih dan data test yang diuji.\n",
    "\n",
    "Dalam implementasi ini, prinsip multi-layered dari MLP kami implementasikan dalam Layer.py, di mana ada class ActivationFunction yang mengandung sigmoid dan linear sebagai dasar dari pengembangan aktivasi network dan class Layer yang mengandung segala informasi mengenai Layer dalam MLP, termasuk input, hidden, dan output layer. \n",
    "\n",
    "Class Layer akan menerima inputan berupa jumlah node, lapisan layer ke-berapa, dan jumlah node pada layer sebelumnya. Kemudian, setiap input yang masuk akan dicek apakah itu adalah layer pertama atau bukan pertama. Jika bukan pertama, akan ditambahkan bias. Kemudian, setiap layer yang terbentuk akan diberi fungsi aktivasi sesuai jenis layernya. Jika layer pertama, diberikan fungsi aktivasi linear. Jika layer kedua, diberikan fungsi aktivasi sigmoid. \n",
    "\n",
    "Kemudian, setiap layer yang terbentuk akan diolah di dalam class MLP di file MLP.py dimana data-data akan selalu diperbaharui dengan flush dan diisi dengan dleta sesuai dengan layernya melalui flushDelta. Kemudian, data yang telah masuk akan di-feed forward untuk nambahkan nilai dari node awal ke nilai akhir. Setelah itu, baru dijalankan algoritma backpropagation, yaitu mencari nilai delta atribut, delta hidden unit, dan delta weight untuk diterapkan pada setiap layer. \n",
    "\n",
    "Setelah itu, akan dijalankan predictionValue dan melakukan fungsi pembelajaran yang terhenti ketika mencapai max iteration, mencapai error minimum, atau mulai diverge. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Hasil Eksekusi dan Perbandingan dengan hasil MLP sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "predictData = data\n",
    "dataHead = list(data.columns)\n",
    "\n",
    "# Shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Creates data by 10 (indexes of data)\n",
    "dataSplitCount = 10\n",
    "dataDict = {n: data.iloc[n:n+dataSplitCount, :] for n in range(0, len(data), dataSplitCount)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. myMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model generator\n",
    "Generates layer to be put in MLP class and return MLP Model\n",
    "\n",
    "Current layer:\n",
    "    x\n",
    "        x   x\n",
    "    x\n",
    "GK      x   x\n",
    "    x\n",
    "        x   x\n",
    "    x\n",
    "\n",
    "Abaikan GK\n",
    "Layer paling kiri adalah keempat input dari 4 atribut iris.csv\n",
    "Layer tengah adalah hidden layer\n",
    "Layer output berfungsi sebagai yang dijelaskan di fungsi outputCheck\n",
    "'''\n",
    "def generateModel(learningRate):\n",
    "    layer0 = Layer(4, 0, 4, ActivationFunction.linear)\n",
    "    layer1 = Layer(3, 1, 4, ActivationFunction.sigmoid)\n",
    "    layer2 = Layer(3, 2, 3, ActivationFunction.sigmoid)\n",
    "    layers = []\n",
    "    layers.append(layer0)\n",
    "    layers.append(layer1)\n",
    "    layers.append(layer2)\n",
    "    return MLP(layers, learningRate)\n",
    "\n",
    "# Do data training\n",
    "'''\n",
    "Create a function that returns the tuple of output node\n",
    "'''\n",
    "def nodeOutputCheck(str):\n",
    "    if (str == \"Versicolor\"):\n",
    "        return [0, 0, 1]\n",
    "    elif (str == \"Virginica\"):\n",
    "        return [0, 1, 0]\n",
    "    elif (str == \"Setosa\"):\n",
    "        return [1, 0, 0]\n",
    "    else:\n",
    "        return [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5d5e2ccfb055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataSplitCount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeOutputCheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminError\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeOutputCheck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Test result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-43a27a2de0e7>\u001b[0m in \u001b[0;36mgenerateModel\u001b[1;34m(learningRate)\u001b[0m\n\u001b[0;32m     18\u001b[0m '''\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mlayer0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivationFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mlayer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivationFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mlayer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivationFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "model = generateModel(0.1)\n",
    "model.learn(dataDict, dataSplitCount, nodeOutputCheck, maxIteration=1000, minError=1)\n",
    "model.predict(predictData, nodeOutputCheck)\n",
    "\n",
    "# Test result\n",
    "for i in range(len(model.layers)):\n",
    "    print(\"Layer: {}\".format(i))\n",
    "    print(np.matrix(model.layers[i].weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLP sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = data[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "target = data[['variety']].replace(['Setosa','Versicolor','Virginica'],[0,1,2])\n",
    "df = pd.concat([df_norm, target], axis=1)\n",
    "testDf = df\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "trainX = df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']]\n",
    "trainY = df[['variety']]\n",
    "\n",
    "testX = df_norm\n",
    "testY = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.960000\n",
      "Test set score: 0.960000\n"
     ]
    }
   ],
   "source": [
    "mlp = skMLP(solver='sgd', alpha=0.1, learning_rate_init=0.1, hidden_layer_sizes=(1,3), activation='logistic', max_iter=1000, random_state=1)\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "\n",
    "prediction = mlp.predict(testX)\n",
    "print(\"Test set score: %f\" % metrics.accuracy_score(prediction,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Pembagian Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NIM      | Nama              | Tugas                                         |\n",
    "|:--------:|:------------------|:----------------------------------------------|\n",
    "| 13517014 | Yoel Susanto      | Feed Forward, Backpropagation, Data Structure |\n",
    "| 13517065 | Andrian Cedric    | Feed Forward, Function, Documentation         |\n",
    "| 13517131 | Jan Meyer Saragih | Feed Forward, Backpropagation, Data Structure |\n",
    "| 13517137 | Vincent Budianto  | Feed Forward, Function, Documentation         |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
